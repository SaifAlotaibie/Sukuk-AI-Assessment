{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Document-Level Split\n",
    "\n",
    "**Goal:** Split 30 PDFs into 20 train / 5 val / 5 test while preserving class balance.  \n",
    "**Constraint:** No model training — split only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1 — Load Data & Compute Per-PDF Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:04.324423Z",
     "iopub.status.busy": "2026-02-18T21:48:04.324124Z",
     "iopub.status.idle": "2026-02-18T21:48:05.397089Z",
     "shell.execute_reply": "2026-02-18T21:48:05.396110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1179 images | 30 PDFs | 5 classes\n",
      "Target split: 20 train / 5 val / 5 test\n",
      "Target image ratio: ~786 / ~196 / ~196\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(\"mini_labels.csv\")\n",
    "df[\"pdf_prefix\"] = df[\"image_name\"].str.replace(r\"_page_\\d+\\.jpg$\", \"\", regex=True)\n",
    "\n",
    "classes = sorted(df[\"label\"].unique())\n",
    "all_pdfs = sorted(df[\"pdf_prefix\"].unique())\n",
    "n_pdfs = len(all_pdfs)\n",
    "\n",
    "global_dist = df[\"label\"].value_counts(normalize=True).reindex(classes).values\n",
    "\n",
    "ct = df.groupby([\"pdf_prefix\", \"label\"]).size().unstack(fill_value=0)\n",
    "for c in classes:\n",
    "    if c not in ct.columns:\n",
    "        ct[c] = 0\n",
    "ct = ct[classes]\n",
    "ct[\"total\"] = ct.sum(axis=1)\n",
    "\n",
    "print(f\"Loaded {len(df)} images | {n_pdfs} PDFs | {len(classes)} classes\")\n",
    "print(f\"Target split: 20 train / 5 val / 5 test\")\n",
    "print(f\"Target image ratio: ~{len(df)*20//30} / ~{len(df)*5//30} / ~{len(df)*5//30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2 — Greedy Balanced Split Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:05.448118Z",
     "iopub.status.busy": "2026-02-18T21:48:05.447892Z",
     "iopub.status.idle": "2026-02-18T21:48:05.459385Z",
     "shell.execute_reply": "2026-02-18T21:48:05.458246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split algorithm defined.\n"
     ]
    }
   ],
   "source": [
    "def compute_split_deviation(pdf_list, ct_df, classes, global_dist):\n",
    "    \"\"\"Compute max absolute deviation of a split's class distribution from global.\"\"\"\n",
    "    if not pdf_list:\n",
    "        return float(\"inf\")\n",
    "    counts = ct_df.loc[pdf_list, classes].sum()\n",
    "    total = counts.sum()\n",
    "    if total == 0:\n",
    "        return float(\"inf\")\n",
    "    split_dist = (counts / total).values\n",
    "    return np.max(np.abs(split_dist - global_dist))\n",
    "\n",
    "\n",
    "def compute_split_cost(pdf_list, ct_df, classes, global_dist):\n",
    "    \"\"\"Sum of squared deviations — lower is better.\"\"\"\n",
    "    if not pdf_list:\n",
    "        return float(\"inf\")\n",
    "    counts = ct_df.loc[pdf_list, classes].sum()\n",
    "    total = counts.sum()\n",
    "    if total == 0:\n",
    "        return float(\"inf\")\n",
    "    split_dist = (counts / total).values\n",
    "    return np.sum((split_dist - global_dist) ** 2)\n",
    "\n",
    "\n",
    "def greedy_split(all_pdfs, ct_df, classes, global_dist,\n",
    "                 n_train=20, n_val=5, n_test=5, seed=42):\n",
    "    \"\"\"\n",
    "    Greedy heuristic:\n",
    "    1. Sort PDFs by page count descending (assign large PDFs first).\n",
    "    2. For each PDF, try adding it to each split that still has room.\n",
    "    3. Pick the assignment that minimizes the combined cost across all 3 splits.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    pdf_order = ct_df.loc[all_pdfs, \"total\"].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "    splits = {\"train\": [], \"val\": [], \"test\": []}\n",
    "    caps = {\"train\": n_train, \"val\": n_val, \"test\": n_test}\n",
    "\n",
    "    for pdf in pdf_order:\n",
    "        best_split = None\n",
    "        best_cost = float(\"inf\")\n",
    "\n",
    "        candidates = [s for s in [\"train\", \"val\", \"test\"] if len(splits[s]) < caps[s]]\n",
    "        rng.shuffle(candidates)  # break ties randomly\n",
    "\n",
    "        for s in candidates:\n",
    "            trial = splits[s] + [pdf]\n",
    "            cost = compute_split_cost(trial, ct_df, classes, global_dist)\n",
    "            # weight val/test higher — their balance matters more with fewer PDFs\n",
    "            if s in (\"val\", \"test\"):\n",
    "                cost *= 2.0\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_split = s\n",
    "\n",
    "        splits[best_split].append(pdf)\n",
    "\n",
    "    return splits\n",
    "\n",
    "print(\"Split algorithm defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3 — Run Split & Select Best Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:05.462527Z",
     "iopub.status.busy": "2026-02-18T21:48:05.462297Z",
     "iopub.status.idle": "2026-02-18T21:48:17.583893Z",
     "shell.execute_reply": "2026-02-18T21:48:17.583103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best seed: 2 (total cost: 0.001172)\n",
      "\n",
      "Train PDFs (20): ['FS1', 'FS10', 'FS11', 'FS12', 'FS15', 'FS17', 'FS18', 'FS19', 'FS22', 'FS3', 'FS4', 'FS7', 'FS9', 'RSF1', 'RSF2', 'RSF3', 'RSF4', 'RSF5', 'RSF6', 'RSF7']\n",
      "Val PDFs   (5):   ['FS13', 'FS16', 'FS20', 'FS21', 'FS5']\n",
      "Test PDFs  (5):  ['FS14', 'FS2', 'FS6', 'FS8', 'RSF8']\n"
     ]
    }
   ],
   "source": [
    "best_splits = None\n",
    "best_total_cost = float(\"inf\")\n",
    "best_seed = None\n",
    "\n",
    "for seed in range(200):\n",
    "    candidate = greedy_split(all_pdfs, ct, classes, global_dist, seed=seed)\n",
    "    cost = sum(\n",
    "        compute_split_cost(candidate[s], ct, classes, global_dist)\n",
    "        for s in [\"train\", \"val\", \"test\"]\n",
    "    )\n",
    "    if cost < best_total_cost:\n",
    "        best_total_cost = cost\n",
    "        best_splits = candidate\n",
    "        best_seed = seed\n",
    "\n",
    "splits = best_splits\n",
    "print(f\"Best seed: {best_seed} (total cost: {best_total_cost:.6f})\")\n",
    "print(f\"\\nTrain PDFs ({len(splits['train'])}): {sorted(splits['train'])}\")\n",
    "print(f\"Val PDFs   ({len(splits['val'])}):   {sorted(splits['val'])}\")\n",
    "print(f\"Test PDFs  ({len(splits['test'])}):  {sorted(splits['test'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4 — Split Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:17.587795Z",
     "iopub.status.busy": "2026-02-18T21:48:17.587601Z",
     "iopub.status.idle": "2026-02-18T21:48:17.611046Z",
     "shell.execute_reply": "2026-02-18T21:48:17.609523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  TRAIN — 20 PDFs, 740 images (62.8%)\n",
      "============================================================\n",
      "  PDFs: ['FS1', 'FS10', 'FS11', 'FS12', 'FS15', 'FS17', 'FS18', 'FS19', 'FS22', 'FS3', 'FS4', 'FS7', 'FS9', 'RSF1', 'RSF2', 'RSF3', 'RSF4', 'RSF5', 'RSF6', 'RSF7']\n",
      "  Class                                Count   Split%  Global%      Dev\n",
      "  ----------------------------------- ------ -------- -------- --------\n",
      "  Financial Sheets                        83    11.2%    10.6%    +0.6%\n",
      "  Independent Auditor's Report            70     9.5%     9.4%    +0.0%\n",
      "  Notes (Tabular)                        338    45.7%    46.4%    -0.7%\n",
      "  Notes (Text)                           205    27.7%    28.0%    -0.3%\n",
      "  Other Pages                             44     5.9%     5.6%    +0.3%\n",
      "\n",
      "  Max absolute deviation: 0.72%\n",
      "\n",
      "============================================================\n",
      "  VAL — 5 PDFs, 219 images (18.6%)\n",
      "============================================================\n",
      "  PDFs: ['FS13', 'FS16', 'FS20', 'FS21', 'FS5']\n",
      "  Class                                Count   Split%  Global%      Dev\n",
      "  ----------------------------------- ------ -------- -------- --------\n",
      "  Financial Sheets                        21     9.6%    10.6%    -1.0%\n",
      "  Independent Auditor's Report            20     9.1%     9.4%    -0.3%\n",
      "  Notes (Tabular)                        107    48.9%    46.4%    +2.5%\n",
      "  Notes (Text)                            61    27.9%    28.0%    -0.1%\n",
      "  Other Pages                             10     4.6%     5.6%    -1.0%\n",
      "\n",
      "  Max absolute deviation: 2.46%\n",
      "\n",
      "============================================================\n",
      "  TEST — 5 PDFs, 220 images (18.7%)\n",
      "============================================================\n",
      "  PDFs: ['FS14', 'FS2', 'FS6', 'FS8', 'RSF8']\n",
      "  Class                                Count   Split%  Global%      Dev\n",
      "  ----------------------------------- ------ -------- -------- --------\n",
      "  Financial Sheets                        21     9.5%    10.6%    -1.1%\n",
      "  Independent Auditor's Report            21     9.5%     9.4%    +0.1%\n",
      "  Notes (Tabular)                        102    46.4%    46.4%    -0.0%\n",
      "  Notes (Text)                            64    29.1%    28.0%    +1.1%\n",
      "  Other Pages                             12     5.5%     5.6%    -0.1%\n",
      "\n",
      "  Max absolute deviation: 1.10%\n"
     ]
    }
   ],
   "source": [
    "def split_stats(split_name, pdf_list, df, ct_df, classes, global_dist):\n",
    "    \"\"\"Print and return stats for one split.\"\"\"\n",
    "    sub = df[df[\"pdf_prefix\"].isin(pdf_list)]\n",
    "    n = len(sub)\n",
    "    counts = sub[\"label\"].value_counts().reindex(classes, fill_value=0)\n",
    "    pcts = counts / n * 100\n",
    "    devs = pcts.values - global_dist * 100\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  {split_name.upper()} — {len(pdf_list)} PDFs, {n} images ({n/len(df)*100:.1f}%)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  PDFs: {sorted(pdf_list)}\")\n",
    "    print(f\"  {'Class':<35} {'Count':>6} {'Split%':>8} {'Global%':>8} {'Dev':>8}\")\n",
    "    print(f\"  {'-'*35} {'-'*6} {'-'*8} {'-'*8} {'-'*8}\")\n",
    "    for i, c in enumerate(classes):\n",
    "        print(f\"  {c:<35} {counts[c]:>6} {pcts[c]:>7.1f}% {global_dist[i]*100:>7.1f}% {devs[i]:>+7.1f}%\")\n",
    "    max_dev = np.max(np.abs(devs))\n",
    "    print(f\"\\n  Max absolute deviation: {max_dev:.2f}%\")\n",
    "    return {\"split\": split_name, \"n_pdfs\": len(pdf_list), \"n_images\": n,\n",
    "            \"pct_images\": round(n / len(df) * 100, 1),\n",
    "            \"class_pcts\": pcts.to_dict(), \"deviations\": dict(zip(classes, devs)),\n",
    "            \"max_dev\": round(max_dev, 2)}\n",
    "\n",
    "stats = {}\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    stats[name] = split_stats(name, splits[name], df, ct, classes, global_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5 — Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:17.613942Z",
     "iopub.status.busy": "2026-02-18T21:48:17.613740Z",
     "iopub.status.idle": "2026-02-18T21:48:17.638331Z",
     "shell.execute_reply": "2026-02-18T21:48:17.636481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PDFs</th>\n",
       "      <th>Images</th>\n",
       "      <th>Images %</th>\n",
       "      <th>Financial Sheets</th>\n",
       "      <th>Financial Sheets dev</th>\n",
       "      <th>Independent Auditor's Report</th>\n",
       "      <th>Independent Auditor's Report dev</th>\n",
       "      <th>Notes (Tabular)</th>\n",
       "      <th>Notes (Tabular) dev</th>\n",
       "      <th>Notes (Text)</th>\n",
       "      <th>Notes (Text) dev</th>\n",
       "      <th>Other Pages</th>\n",
       "      <th>Other Pages dev</th>\n",
       "      <th>Max Dev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>20</td>\n",
       "      <td>740</td>\n",
       "      <td>62.8</td>\n",
       "      <td>11.2%</td>\n",
       "      <td>+0.6%</td>\n",
       "      <td>9.5%</td>\n",
       "      <td>+0.0%</td>\n",
       "      <td>45.7%</td>\n",
       "      <td>-0.7%</td>\n",
       "      <td>27.7%</td>\n",
       "      <td>-0.3%</td>\n",
       "      <td>5.9%</td>\n",
       "      <td>+0.3%</td>\n",
       "      <td>0.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "      <td>219</td>\n",
       "      <td>18.6</td>\n",
       "      <td>9.6%</td>\n",
       "      <td>-1.0%</td>\n",
       "      <td>9.1%</td>\n",
       "      <td>-0.3%</td>\n",
       "      <td>48.9%</td>\n",
       "      <td>+2.5%</td>\n",
       "      <td>27.9%</td>\n",
       "      <td>-0.1%</td>\n",
       "      <td>4.6%</td>\n",
       "      <td>-1.0%</td>\n",
       "      <td>2.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>18.7</td>\n",
       "      <td>9.5%</td>\n",
       "      <td>-1.1%</td>\n",
       "      <td>9.5%</td>\n",
       "      <td>+0.1%</td>\n",
       "      <td>46.4%</td>\n",
       "      <td>-0.0%</td>\n",
       "      <td>29.1%</td>\n",
       "      <td>+1.1%</td>\n",
       "      <td>5.5%</td>\n",
       "      <td>-0.1%</td>\n",
       "      <td>1.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLOBAL</th>\n",
       "      <td>30</td>\n",
       "      <td>1179</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.6%</td>\n",
       "      <td>—</td>\n",
       "      <td>9.4%</td>\n",
       "      <td>—</td>\n",
       "      <td>46.4%</td>\n",
       "      <td>—</td>\n",
       "      <td>28.0%</td>\n",
       "      <td>—</td>\n",
       "      <td>5.6%</td>\n",
       "      <td>—</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PDFs  Images  Images % Financial Sheets Financial Sheets dev Independent Auditor's Report Independent Auditor's Report dev Notes (Tabular) Notes (Tabular) dev Notes (Text) Notes (Text) dev Other Pages  \\\n",
       "Split                                                                                                                                                                                                              \n",
       "train     20     740      62.8            11.2%                +0.6%                         9.5%                            +0.0%           45.7%               -0.7%        27.7%            -0.3%        5.9%   \n",
       "val        5     219      18.6             9.6%                -1.0%                         9.1%                            -0.3%           48.9%               +2.5%        27.9%            -0.1%        4.6%   \n",
       "test       5     220      18.7             9.5%                -1.1%                         9.5%                            +0.1%           46.4%               -0.0%        29.1%            +1.1%        5.5%   \n",
       "GLOBAL    30    1179     100.0            10.6%                    —                         9.4%                                —           46.4%                   —        28.0%                —        5.6%   \n",
       "\n",
       "       Other Pages dev Max Dev  \n",
       "Split                           \n",
       "train            +0.3%   0.72%  \n",
       "val              -1.0%   2.46%  \n",
       "test             -0.1%   1.10%  \n",
       "GLOBAL               —       —  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    row = {\"Split\": name, \"PDFs\": stats[name][\"n_pdfs\"],\n",
    "           \"Images\": stats[name][\"n_images\"],\n",
    "           \"Images %\": stats[name][\"pct_images\"]}\n",
    "    for c in classes:\n",
    "        row[c] = f\"{stats[name]['class_pcts'][c]:.1f}%\"\n",
    "        row[f\"{c} dev\"] = f\"{stats[name]['deviations'][c]:+.1f}%\"\n",
    "    row[\"Max Dev\"] = f\"{stats[name]['max_dev']:.2f}%\"\n",
    "    rows.append(row)\n",
    "\n",
    "# add global row\n",
    "g_row = {\"Split\": \"GLOBAL\", \"PDFs\": n_pdfs, \"Images\": len(df), \"Images %\": 100.0}\n",
    "for i, c in enumerate(classes):\n",
    "    g_row[c] = f\"{global_dist[i]*100:.1f}%\"\n",
    "    g_row[f\"{c} dev\"] = \"—\"\n",
    "g_row[\"Max Dev\"] = \"—\"\n",
    "rows.append(g_row)\n",
    "\n",
    "comp = pd.DataFrame(rows).set_index(\"Split\")\n",
    "with pd.option_context(\"display.max_columns\", None, \"display.width\", 220):\n",
    "    display(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6 — Save Split CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:17.640604Z",
     "iopub.status.busy": "2026-02-18T21:48:17.640375Z",
     "iopub.status.idle": "2026-02-18T21:48:17.665100Z",
     "shell.execute_reply": "2026-02-18T21:48:17.663948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_doc_split.csv — 740 rows\n",
      "Saved val_doc_split.csv — 219 rows\n",
      "Saved test_doc_split.csv — 220 rows\n"
     ]
    }
   ],
   "source": [
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    sub = df[df[\"pdf_prefix\"].isin(splits[name])][[\"image_name\", \"label\", \"pdf_prefix\"]].copy()\n",
    "    sub = sub.sort_values([\"pdf_prefix\", \"image_name\"]).reset_index(drop=True)\n",
    "    path = f\"{name}_doc_split.csv\"\n",
    "    sub.to_csv(path, index=False)\n",
    "    print(f\"Saved {path} — {len(sub)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7 — Generate Split Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-18T21:48:17.667349Z",
     "iopub.status.busy": "2026-02-18T21:48:17.667176Z",
     "iopub.status.idle": "2026-02-18T21:48:17.688256Z",
     "shell.execute_reply": "2026-02-18T21:48:17.686694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report written to /Users/ta/Desktop/Sukuk-AI-Assessment/DOCUMENT_LEVEL_SPLIT_REPORT.md\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "lines.append(\"# Document-Level Split Report\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"---\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# --- Overview ---\n",
    "lines.append(\"## 1. Split Overview\")\n",
    "lines.append(\"\")\n",
    "lines.append(f\"- **Total images:** {len(df)}\")\n",
    "lines.append(f\"- **Total PDFs:** {n_pdfs}\")\n",
    "lines.append(f\"- **Split ratio (PDFs):** 20 / 5 / 5\")\n",
    "lines.append(f\"- **Algorithm:** Greedy heuristic — assign largest PDFs first, minimizing class-distribution deviation\")\n",
    "lines.append(f\"- **Best seed:** {best_seed}\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# --- PDFs per split ---\n",
    "lines.append(\"## 2. PDFs per Split\")\n",
    "lines.append(\"\")\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    s = stats[name]\n",
    "    lines.append(f\"### {name.capitalize()} — {s['n_pdfs']} PDFs, {s['n_images']} images ({s['pct_images']}%)\")\n",
    "    lines.append(\"\")\n",
    "    for pdf in sorted(splits[name]):\n",
    "        pages = int(ct.loc[pdf, 'total'])\n",
    "        lines.append(f\"- {pdf} ({pages} pages)\")\n",
    "    lines.append(\"\")\n",
    "\n",
    "# --- Image counts ---\n",
    "lines.append(\"## 3. Image Counts\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"| Split | PDFs | Images | % of Total |\")\n",
    "lines.append(\"|-------|-----:|-------:|-----------:|\")\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    s = stats[name]\n",
    "    lines.append(f\"| {name.capitalize()} | {s['n_pdfs']} | {s['n_images']} | {s['pct_images']}% |\")\n",
    "lines.append(f\"| **Total** | **{n_pdfs}** | **{len(df)}** | **100.0%** |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# --- Class distribution per split ---\n",
    "lines.append(\"## 4. Class Distribution per Split\")\n",
    "lines.append(\"\")\n",
    "header = \"| Split | \" + \" | \".join(classes) + \" |\"\n",
    "sep = \"| --- | \" + \" | \".join([\"---:\"]*len(classes)) + \" |\"\n",
    "lines.append(header)\n",
    "lines.append(sep)\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    vals = \" | \".join(f\"{stats[name]['class_pcts'][c]:.1f}%\" for c in classes)\n",
    "    lines.append(f\"| {name.capitalize()} | {vals} |\")\n",
    "global_vals = \" | \".join(f\"{global_dist[i]*100:.1f}%\" for i in range(len(classes)))\n",
    "lines.append(f\"| **Global** | {global_vals} |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# --- Deviation ---\n",
    "lines.append(\"## 5. Deviation from Global Distribution\")\n",
    "lines.append(\"\")\n",
    "header = \"| Split | \" + \" | \".join(classes) + \" | Max Dev |\"\n",
    "sep = \"| --- | \" + \" | \".join([\"---:\"]*len(classes)) + \" | ---: |\"\n",
    "lines.append(header)\n",
    "lines.append(sep)\n",
    "for name in [\"train\", \"val\", \"test\"]:\n",
    "    vals = \" | \".join(f\"{stats[name]['deviations'][c]:+.1f}%\" for c in classes)\n",
    "    lines.append(f\"| {name.capitalize()} | {vals} | {stats[name]['max_dev']:.2f}% |\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# --- Recommendation ---\n",
    "lines.append(\"## 6. Recommendation\")\n",
    "lines.append(\"\")\n",
    "all_devs = [stats[s][\"max_dev\"] for s in [\"train\", \"val\", \"test\"]]\n",
    "worst_dev = max(all_devs)\n",
    "worst_split = [\"train\", \"val\", \"test\"][all_devs.index(worst_dev)]\n",
    "\n",
    "if worst_dev < 3.0:\n",
    "    verdict = \"EXCELLENT\"\n",
    "    detail = \"All splits have class distributions within 3 percentage points of the global distribution. This split is well-balanced and ready for use.\"\n",
    "elif worst_dev < 5.0:\n",
    "    verdict = \"ACCEPTABLE\"\n",
    "    detail = f\"Maximum deviation is {worst_dev:.1f}% in the {worst_split} split. This is within acceptable tolerance for a document-level split with only 30 PDFs.\"\n",
    "else:\n",
    "    verdict = \"MARGINAL\"\n",
    "    detail = f\"Maximum deviation is {worst_dev:.1f}% in the {worst_split} split. Consider manual adjustment of borderline PDFs.\"\n",
    "\n",
    "lines.append(f\"**Verdict: {verdict}**\")\n",
    "lines.append(\"\")\n",
    "lines.append(detail)\n",
    "lines.append(\"\")\n",
    "lines.append(\"### Key observations\")\n",
    "lines.append(\"\")\n",
    "lines.append(f\"- Worst-case maximum deviation: **{worst_dev:.2f}%** ({worst_split} split)\")\n",
    "lines.append(f\"- All 5 classes are represented in every split.\")\n",
    "\n",
    "# check skew spread\n",
    "skewed_pdf = \"FS19\"\n",
    "for s in [\"train\", \"val\", \"test\"]:\n",
    "    if skewed_pdf in splits[s]:\n",
    "        lines.append(f\"- Skewed PDF ({skewed_pdf}) placed in **{s}** split.\")\n",
    "        break\n",
    "\n",
    "# check outlier spread\n",
    "outlier_pdfs = [\"FS19\", \"RSF8\", \"RSF3\", \"RSF4\", \"RSF7\", \"FS11\", \"FS3\",\n",
    "                \"FS12\", \"FS4\", \"FS17\", \"RSF2\", \"FS22\", \"RSF1\"]\n",
    "for s in [\"train\", \"val\", \"test\"]:\n",
    "    in_split = [p for p in outlier_pdfs if p in splits[s]]\n",
    "    lines.append(f\"- Outlier PDFs in {s}: {len(in_split)} — {sorted(in_split)}\")\n",
    "\n",
    "lines.append(\"\")\n",
    "lines.append(\"### Files generated\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"- `train_doc_split.csv`\")\n",
    "lines.append(\"- `val_doc_split.csv`\")\n",
    "lines.append(\"- `test_doc_split.csv`\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"---\")\n",
    "lines.append(\"\")\n",
    "lines.append(\"*Report generated automatically by DOCUMENT_LEVEL_SPLIT.ipynb — no model training performed.*\")\n",
    "\n",
    "report_path = Path(\"DOCUMENT_LEVEL_SPLIT_REPORT.md\")\n",
    "report_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"Report written to {report_path.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
