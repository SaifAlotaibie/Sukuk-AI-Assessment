{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline Transfer Learning — EfficientNet-B0\n",
        "\n",
        "Document page classification with two-stage transfer learning.  \n",
        "**Read-only with respect to the split** — uses existing `train/val/test_doc_split.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import copy, time, random\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else\n",
        "                       \"mps\" if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available() else\n",
        "                       \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 1 — Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMAGE_DIR = Path(\"pages_raw\")\n",
        "\n",
        "train_df = pd.read_csv(\"train_doc_split.csv\")\n",
        "val_df   = pd.read_csv(\"val_doc_split.csv\")\n",
        "test_df  = pd.read_csv(\"test_doc_split.csv\")\n",
        "\n",
        "classes = sorted(train_df[\"label\"].unique())\n",
        "label2idx = {c: i for i, c in enumerate(classes)}\n",
        "idx2label = {i: c for c, i in label2idx.items()}\n",
        "\n",
        "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "print(f\"Classes ({len(classes)}): {classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_to_square(img):\n",
        "    w, h = img.size\n",
        "    max_dim = max(w, h)\n",
        "    new_img = Image.new(\"RGB\", (max_dim, max_dim), (255, 255, 255))\n",
        "    new_img.paste(img, ((max_dim - w) // 2, (max_dim - h) // 2))\n",
        "    return new_img\n",
        "\n",
        "\n",
        "class DocPageDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, transform):\n",
        "        self.records = df.reset_index(drop=True)\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.records.iloc[idx]\n",
        "        img = Image.open(self.image_dir / row[\"image_name\"]).convert(\"RGB\")\n",
        "        img = pad_to_square(img)\n",
        "        img = self.transform(img)\n",
        "        label = label2idx[row[\"label\"]]\n",
        "        return img, label\n",
        "\n",
        "\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(2),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = DocPageDataset(train_df, IMAGE_DIR, train_transform)\n",
        "val_ds   = DocPageDataset(val_df,   IMAGE_DIR, eval_transform)\n",
        "test_ds  = DocPageDataset(test_df,  IMAGE_DIR, eval_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0, drop_last=False)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Batches — train: {len(train_loader)}, val: {len(val_loader)}, test: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 2 — Handle Class Imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_counts = train_df[\"label\"].value_counts().reindex(classes).values.astype(float)\n",
        "inv_freq = 1.0 / class_counts\n",
        "class_weights = inv_freq / inv_freq.sum() * len(classes)\n",
        "class_weights_t = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "print(\"Class weights (inverse-frequency, normalized):\")\n",
        "for c, w in zip(classes, class_weights):\n",
        "    print(f\"  {c:<35} {w:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 3 — Model Setup & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.3),\n",
        "    nn.Linear(in_features, len(classes)),\n",
        ")\n",
        "model = model.to(device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total params: {total_params:,}\")\n",
        "print(f\"Trainable:    {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss(weight=class_weights_t)\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(imgs), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "    return running_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "def evaluate_epoch(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            out = model(imgs)\n",
        "            running_loss += criterion(out, labels).item() * imgs.size(0)\n",
        "            all_preds.extend(out.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    n = len(loader.dataset)\n",
        "    avg_loss = running_loss / n\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1m = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "    return avg_loss, acc, f1m\n",
        "\n",
        "\n",
        "print(\"Training utilities ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Stage 1: frozen backbone ----\n",
        "for p in model.features.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "optimizer1 = optim.AdamW(model.classifier.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "history = {\"epoch\": [], \"stage\": [], \"train_loss\": [], \"val_loss\": [], \"val_acc\": [], \"val_f1\": []}\n",
        "\n",
        "print(\"Stage 1 — Frozen backbone, training classifier head (5 epochs)\")\n",
        "print(f\"{'Epoch':>5} {'Train Loss':>11} {'Val Loss':>11} {'Val Acc':>9} {'Val F1':>9}\")\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    t0 = time.time()\n",
        "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer1)\n",
        "    vl_loss, vl_acc, vl_f1 = evaluate_epoch(model, val_loader, criterion)\n",
        "    elapsed = time.time() - t0\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    history[\"stage\"].append(1)\n",
        "    history[\"train_loss\"].append(tr_loss)\n",
        "    history[\"val_loss\"].append(vl_loss)\n",
        "    history[\"val_acc\"].append(vl_acc)\n",
        "    history[\"val_f1\"].append(vl_f1)\n",
        "    print(f\"{epoch:>5} {tr_loss:>11.4f} {vl_loss:>11.4f} {vl_acc:>8.1%} {vl_f1:>8.4f}  ({elapsed:.0f}s)\")\n",
        "\n",
        "print(\"Stage 1 complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Stage 2: full fine-tuning with discriminative LR ----\n",
        "for p in model.features.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer2 = optim.AdamW([\n",
        "    {\"params\": model.features.parameters(), \"lr\": 1e-4},\n",
        "    {\"params\": model.classifier.parameters(), \"lr\": 1e-3},\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer2, T_max=30)\n",
        "\n",
        "PATIENCE = 7\n",
        "MAX_EPOCHS = 30\n",
        "best_val_f1 = max(history[\"val_f1\"])\n",
        "best_model_state = copy.deepcopy(model.state_dict())\n",
        "best_epoch = history[\"epoch\"][int(np.argmax(history[\"val_f1\"]))]\n",
        "best_val_loss = min(history[\"val_loss\"])\n",
        "patience_counter = 0\n",
        "\n",
        "print(f\"Stage 2 — Full fine-tuning (up to {MAX_EPOCHS} epochs, patience={PATIENCE})\")\n",
        "print(f\"{'Epoch':>5} {'Train Loss':>11} {'Val Loss':>11} {'Val Acc':>9} {'Val F1':>9} {'Note'}\")\n",
        "\n",
        "for epoch in range(1, MAX_EPOCHS + 1):\n",
        "    global_epoch = 5 + epoch\n",
        "    t0 = time.time()\n",
        "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer2)\n",
        "    vl_loss, vl_acc, vl_f1 = evaluate_epoch(model, val_loader, criterion)\n",
        "    scheduler.step()\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    history[\"epoch\"].append(global_epoch)\n",
        "    history[\"stage\"].append(2)\n",
        "    history[\"train_loss\"].append(tr_loss)\n",
        "    history[\"val_loss\"].append(vl_loss)\n",
        "    history[\"val_acc\"].append(vl_acc)\n",
        "    history[\"val_f1\"].append(vl_f1)\n",
        "\n",
        "    note = \"\"\n",
        "    if vl_f1 > best_val_f1:\n",
        "        best_val_f1 = vl_f1\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        best_epoch = global_epoch\n",
        "        note += \" *best_f1*\"\n",
        "\n",
        "    if vl_loss < best_val_loss:\n",
        "        best_val_loss = vl_loss\n",
        "        patience_counter = 0\n",
        "        note += \" +loss\"\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    print(f\"{global_epoch:>5} {tr_loss:>11.4f} {vl_loss:>11.4f} {vl_acc:>8.1%} {vl_f1:>8.4f}  ({elapsed:.0f}s){note}\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f\"\\nEarly stopping at epoch {global_epoch} (patience={PATIENCE}).\")\n",
        "        break\n",
        "\n",
        "model.load_state_dict(best_model_state)\n",
        "print(f\"\\nBest model from epoch {best_epoch} (val macro-F1 = {best_val_f1:.4f})\")\n",
        "torch.save(best_model_state, \"baseline_efficientnet_b0.pth\")\n",
        "print(\"Model saved to baseline_efficientnet_b0.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "epochs = history[\"epoch\"]\n",
        "stage1_end = 5\n",
        "\n",
        "axes[0].plot(epochs, history[\"train_loss\"], label=\"Train\")\n",
        "axes[0].plot(epochs, history[\"val_loss\"], label=\"Val\")\n",
        "axes[0].axvline(stage1_end, color=\"gray\", ls=\"--\", alpha=0.5, label=\"Stage 1→2\")\n",
        "axes[0].set_title(\"Loss\"); axes[0].set_xlabel(\"Epoch\"); axes[0].legend()\n",
        "\n",
        "axes[1].plot(epochs, history[\"val_acc\"])\n",
        "axes[1].axvline(stage1_end, color=\"gray\", ls=\"--\", alpha=0.5)\n",
        "axes[1].set_title(\"Val Accuracy\"); axes[1].set_xlabel(\"Epoch\")\n",
        "\n",
        "axes[2].plot(epochs, history[\"val_f1\"])\n",
        "axes[2].axvline(stage1_end, color=\"gray\", ls=\"--\", alpha=0.5)\n",
        "axes[2].set_title(\"Val Macro F1\"); axes[2].set_xlabel(\"Epoch\")\n",
        "\n",
        "plt.tight_layout()\n",
        "Path(\"baseline_visuals\").mkdir(exist_ok=True)\n",
        "plt.savefig(\"baseline_visuals/training_curves.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"Saved training_curves.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 4 — Baseline Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def full_evaluation(model, loader, split_name):\n",
        "    model.eval()\n",
        "    all_preds, all_labels, all_confs = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            out = model(imgs)\n",
        "            probs = torch.softmax(out, dim=1)\n",
        "            confs, preds = probs.max(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_confs.extend(confs.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_confs = np.array(all_confs)\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1_mac = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
        "    f1_wt  = f1_score(all_labels, all_preds, average=\"weighted\", zero_division=0)\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                   target_names=classes, zero_division=0)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  {split_name.upper()} SET EVALUATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Accuracy:    {acc:.4f}\")\n",
        "    print(f\"  Macro F1:    {f1_mac:.4f}\")\n",
        "    print(f\"  Weighted F1: {f1_wt:.4f}\")\n",
        "    print(f\"\\n{report}\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=classes, yticklabels=classes, ax=ax)\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "    ax.set_title(f\"Confusion Matrix — {split_name.capitalize()}\")\n",
        "    plt.tight_layout()\n",
        "    cm_path = f\"baseline_visuals/cm_{split_name}.png\"\n",
        "    plt.savefig(cm_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc, \"macro_f1\": f1_mac, \"weighted_f1\": f1_wt,\n",
        "        \"report\": report, \"cm\": cm, \"cm_path\": cm_path,\n",
        "        \"preds\": all_preds, \"labels\": all_labels, \"confs\": all_confs,\n",
        "    }\n",
        "\n",
        "print(\"Evaluation function ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_results  = full_evaluation(model, val_loader, \"validation\")\n",
        "test_results = full_evaluation(model, test_loader, \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 5 — Visual Prediction Analysis & Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_image_names = val_df[\"image_name\"].values\n",
        "preds  = val_results[\"preds\"]\n",
        "labels = val_results[\"labels\"]\n",
        "confs  = val_results[\"confs\"]\n",
        "\n",
        "correct_idx = np.where(preds == labels)[0]\n",
        "wrong_idx   = np.where(preds != labels)[0]\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "n_correct = min(10, len(correct_idx))\n",
        "n_wrong   = min(10, len(wrong_idx))\n",
        "sample_correct = rng.choice(correct_idx, n_correct, replace=False) if n_correct else []\n",
        "sample_wrong   = rng.choice(wrong_idx,   n_wrong,   replace=False) if n_wrong else []\n",
        "\n",
        "print(f\"Correct predictions available: {len(correct_idx)} — sampled {n_correct}\")\n",
        "print(f\"Wrong   predictions available: {len(wrong_idx)} — sampled {n_wrong}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_prediction_grid(indices, title, filename):\n",
        "    if len(indices) == 0:\n",
        "        print(f\"No samples for '{title}'\")\n",
        "        return\n",
        "    n = len(indices)\n",
        "    cols = min(5, n)\n",
        "    rows = (n + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 5 * rows))\n",
        "    if rows == 1 and cols == 1:\n",
        "        axes = np.array([axes])\n",
        "    axes = np.atleast_2d(axes)\n",
        "\n",
        "    for pos, idx in enumerate(indices):\n",
        "        r, c = divmod(pos, cols)\n",
        "        ax = axes[r, c]\n",
        "        img = Image.open(IMAGE_DIR / val_image_names[idx]).convert(\"RGB\")\n",
        "        ax.imshow(img)\n",
        "        true_lbl = idx2label[labels[idx]]\n",
        "        pred_lbl = idx2label[preds[idx]]\n",
        "        conf = confs[idx]\n",
        "        color = \"green\" if true_lbl == pred_lbl else \"red\"\n",
        "        ax.set_title(f\"{val_image_names[idx]}\\nTrue: {true_lbl}\\nPred: {pred_lbl}\\nConf: {conf:.1%}\",\n",
        "                     fontsize=8, color=color)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    for pos in range(len(indices), rows * cols):\n",
        "        r, c = divmod(pos, cols)\n",
        "        axes[r, c].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"Saved {filename}\")\n",
        "\n",
        "\n",
        "save_prediction_grid(sample_correct,\n",
        "                     \"Correct Predictions (Validation)\",\n",
        "                     \"baseline_visuals/correct_predictions.png\")\n",
        "\n",
        "save_prediction_grid(sample_wrong,\n",
        "                     \"Misclassified Samples (Validation)\",\n",
        "                     \"baseline_visuals/misclassified_samples.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lines = []\n",
        "lines.append(\"# Baseline Transfer Learning Report\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"---\")\n",
        "lines.append(\"\")\n",
        "\n",
        "# ---- Section 1: Training Summary ----\n",
        "lines.append(\"## 1. Training Summary\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"| Parameter | Value |\")\n",
        "lines.append(\"|-----------|-------|\")\n",
        "lines.append(\"| Model | EfficientNet-B0 (ImageNet pretrained) |\")\n",
        "lines.append(f\"| Total parameters | {total_params:,} |\")\n",
        "lines.append(\"| Input size | 224 x 224 |\")\n",
        "lines.append(\"| Preprocessing | Pad to square (white), resize, ImageNet normalize |\")\n",
        "lines.append(\"| Train augmentations | Rotation ±2°, Brightness ±10%, Contrast ±10% |\")\n",
        "lines.append(f\"| Batch size | {BATCH_SIZE} |\")\n",
        "lines.append(\"| Loss | Weighted CrossEntropyLoss (inverse-frequency) |\")\n",
        "lines.append(\"| Stage 1 | Frozen backbone, 5 epochs, LR=1e-3 |\")\n",
        "lines.append(\"| Stage 2 | Full fine-tune, backbone LR=1e-4, head LR=1e-3, CosineAnnealing |\")\n",
        "lines.append(f\"| Early stopping | Patience={PATIENCE} on val loss |\")\n",
        "lines.append(f\"| Best epoch | {best_epoch} |\")\n",
        "lines.append(f\"| Best val macro F1 | {best_val_f1:.4f} |\")\n",
        "lines.append(f\"| Total epochs trained | {history['epoch'][-1]} |\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Training Curves\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"![Training Curves](baseline_visuals/training_curves.png)\")\n",
        "lines.append(\"\")\n",
        "\n",
        "# ---- Section 2: Validation Metrics ----\n",
        "lines.append(\"## 2. Validation Metrics\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"| Metric | Value |\")\n",
        "lines.append(\"|--------|------:|\")\n",
        "lines.append(f\"| Accuracy | {val_results['accuracy']:.4f} |\")\n",
        "lines.append(f\"| Macro F1 | {val_results['macro_f1']:.4f} |\")\n",
        "lines.append(f\"| Weighted F1 | {val_results['weighted_f1']:.4f} |\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Classification Report (Validation)\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"```\")\n",
        "lines.append(val_results[\"report\"].strip())\n",
        "lines.append(\"```\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Confusion Matrix (Validation)\")\n",
        "lines.append(\"\")\n",
        "lines.append(f\"![Confusion Matrix — Validation]({val_results['cm_path']})\")\n",
        "lines.append(\"\")\n",
        "\n",
        "# ---- Section 3: Test Metrics ----\n",
        "lines.append(\"## 3. Test Metrics\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"| Metric | Value |\")\n",
        "lines.append(\"|--------|------:|\")\n",
        "lines.append(f\"| Accuracy | {test_results['accuracy']:.4f} |\")\n",
        "lines.append(f\"| Macro F1 | {test_results['macro_f1']:.4f} |\")\n",
        "lines.append(f\"| Weighted F1 | {test_results['weighted_f1']:.4f} |\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Classification Report (Test)\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"```\")\n",
        "lines.append(test_results[\"report\"].strip())\n",
        "lines.append(\"```\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Confusion Matrix (Test)\")\n",
        "lines.append(\"\")\n",
        "lines.append(f\"![Confusion Matrix — Test]({test_results['cm_path']})\")\n",
        "lines.append(\"\")\n",
        "\n",
        "# ---- Section 4: Visual Evaluation ----\n",
        "lines.append(\"## 4. Visual Evaluation\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"### Correct Predictions\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"![Correct Predictions](baseline_visuals/correct_predictions.png)\")\n",
        "lines.append(\"\")\n",
        "if n_correct > 0:\n",
        "    lines.append(\"| # | Image | True Label | Predicted | Confidence |\")\n",
        "    lines.append(\"|---|-------|-----------|-----------|-----------|\")\n",
        "    for i, idx in enumerate(sample_correct, 1):\n",
        "        lines.append(f\"| {i} | {val_image_names[idx]} | {idx2label[labels[idx]]} | {idx2label[preds[idx]]} | {confs[idx]:.1%} |\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "lines.append(\"### Misclassified Samples\")\n",
        "lines.append(\"\")\n",
        "if n_wrong > 0:\n",
        "    lines.append(\"![Misclassified Samples](baseline_visuals/misclassified_samples.png)\")\n",
        "    lines.append(\"\")\n",
        "    lines.append(\"| # | Image | True Label | Predicted | Confidence |\")\n",
        "    lines.append(\"|---|-------|-----------|-----------|-----------|\")\n",
        "    for i, idx in enumerate(sample_wrong, 1):\n",
        "        lines.append(f\"| {i} | {val_image_names[idx]} | {idx2label[labels[idx]]} | {idx2label[preds[idx]]} | {confs[idx]:.1%} |\")\n",
        "    lines.append(\"\")\n",
        "else:\n",
        "    lines.append(\"No misclassified samples in the validation set.\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "lines.append(\"---\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"*Report generated by BASELINE_TRAINING.ipynb — no dataset modifications made.*\")\n",
        "\n",
        "report_path = Path(\"BASELINE_TRANSFER_LEARNING_REPORT.md\")\n",
        "report_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "print(f\"\\nReport saved to {report_path}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"  FINAL SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  Model:       EfficientNet-B0\")\n",
        "print(f\"  Best epoch:  {best_epoch}\")\n",
        "print(f\"  Val  — Acc: {val_results['accuracy']:.4f}  Macro-F1: {val_results['macro_f1']:.4f}  Weighted-F1: {val_results['weighted_f1']:.4f}\")\n",
        "print(f\"  Test — Acc: {test_results['accuracy']:.4f}  Macro-F1: {test_results['macro_f1']:.4f}  Weighted-F1: {test_results['weighted_f1']:.4f}\")\n",
        "print(f\"{'='*60}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
